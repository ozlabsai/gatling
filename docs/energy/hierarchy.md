# E_hierarchy: Hierarchy Energy Critic

**Component ID:** EGA-001
**Status:** Complete
**Workstream:** Energy Geometry (Yilun Du / Michael Freedman)

## Overview

E_hierarchy is the first energy critic in the Product of Experts (PoE) energy composition. It detects when untrusted data from external sources (RAG, web scraping) inappropriately influences control flow or decision-making logic in execution plans.

## Purpose

In agentic systems, a critical vulnerability occurs when untrusted retrieval results steer the agent's actions. E_hierarchy penalizes plans where:
- Low-trust data (TrustTier.PUBLIC_WEB) determines which tools to invoke
- RAG-injected instructions override internal policy
- Control flow decisions derive from unverified sources

## Mathematical Formulation

```
E_hierarchy(z_g, z_e) = α * E_head(M_control ⊙ M_importance ⊙ (z_e - z_g))
```

Where:
- `z_g`: Governance latent from GovernanceEncoder ∈ R^1024
- `z_e`: Execution latent from ExecutionEncoder ∈ R^1024
- `M_control`: Learned attention mask identifying control-flow dimensions
- `M_importance`: Learned weights for security-critical deviations
- `⊙`: Element-wise (Hadamard) product
- `α`: Learned scaling factor for PoE composition
- `E_head`: Neural projection to scalar energy

## Architecture

### 1. Control-Flow Detector
```python
control_query: nn.Sequential(
    Linear(1024 → 256),
    LayerNorm,
    GELU,
    Dropout(0.1),
    Linear(256 → 4)  # 4 attention heads
)
```

Uses multi-head attention to identify which latent dimensions encode control logic vs. data scope/tool selection.

### 2. Importance Scorer
```python
importance_scorer: nn.Sequential(
    Linear(2048 → 256),  # Concat(z_g, z_e)
    LayerNorm,
    GELU,
    Dropout(0.1),
    Linear(256 → 1024),
    Sigmoid  # Output ∈ [0, 1]
)
```

Learns to weight dimensions by security criticality - not all mismatches are equally dangerous.

### 3. Energy Head
```python
energy_head: nn.Sequential(
    Linear(1024 → 128),
    GELU,
    Dropout(0.1),
    Linear(128 → 1)
)
```

Projects weighted deviation to scalar energy value.

## Training

E_hierarchy is trained jointly with the JEPA encoders using **InfoNCE contrastive loss**:

```python
# Positive pairs: (policy, safe_plan)
E_positive = E_hierarchy(z_g, z_e_safe)

# Hard negatives: (policy, corrupted_plan)
E_negative = E_hierarchy(z_g, z_e_corrupted)

# Enforce energy gap
loss = max(0, δ_sec - (E_negative - E_positive))
```

Where:
- δ_sec: Security margin (calibrated to ensure 99.9% detection)
- Hard negatives generated by Corrupter Agent (Kolter workstream)

## Usage

### Standalone Inference
```python
from source.energy.hierarchy import HierarchyEnergyFunction

# Initialize
energy_fn = HierarchyEnergyFunction(latent_dim=1024)

# Compute energy
energy = energy_fn(z_g, z_e)  # Returns scalar tensor

# Get diagnostic breakdown
decomp = energy_fn.get_energy_decomposition(z_g, z_e)
# Returns: {total_energy, deviation_norm, control_focus, ...}
```

### Integration with Encoders
```python
from source.encoders.governance_encoder import GovernanceEncoder, PolicySchema
from source.encoders.execution_encoder import ExecutionEncoder, ExecutionPlan
from source.energy.hierarchy import HierarchyEnergyFunction

gov_encoder = GovernanceEncoder()
exec_encoder = ExecutionEncoder()
energy_fn = HierarchyEnergyFunction()

# Encode policy and plan
z_g = gov_encoder(policy)
z_e = exec_encoder(plan)

# Compute hierarchy energy
energy = energy_fn(z_g, z_e)
```

## Performance

Measured on M-series MacBook Pro (CPU inference):

| Metric | Value | Target | Status |
|--------|-------|--------|--------|
| Single inference latency | 0.53 ms | <20 ms | ✅ 37x better |
| Batch latency (per sample) | 0.36 ms | <10 ms | ✅ 27x better |
| Model size | 4.51 MB | <50 MB | ✅ |
| Parameter count | 1.15M | <5M | ✅ |

## Implementation Details

**File:** `source/energy/hierarchy.py`
**Tests:** `test/test_energy/test_hierarchy.py` (30 tests, 100% passing)
**Dependencies:**
- torch >= 2.5.0
- No external energy function libraries

## Key Design Decisions

1. **Attention-based control detection** over fixed masks
   - Rationale: Different policies have different control-flow semantics
   - Trade-off: +1M params but adaptable to diverse domains

2. **Learned importance weighting**
   - Rationale: Not all deviations indicate security risk
   - Trade-off: Requires sufficient training data for calibration

3. **Separate alpha scaling parameter**
   - Rationale: Enables compositional balance with E_provenance, E_scope, E_flow
   - Trade-off: Must be tuned during PoE composition

## Integration with Other Energy Terms

E_hierarchy is composed with other critics in the Product of Experts:

```python
E_total = E_hierarchy(z_g, z_e) +
          E_provenance(z_g, z_e) +
          E_scope(z_g, z_e) +
          E_flow(z_g, z_e)
```

The learned `alpha` parameter ensures E_hierarchy contributes appropriately without dominating the composite energy.

## Diagnostic Tools

### Energy Decomposition
```python
decomp = energy_fn.get_energy_decomposition(z_g, z_e)

print(f"Total energy: {decomp['total_energy']}")
print(f"Top control dims: {decomp['top_control_dims']}")
print(f"Control focus: {decomp['control_focus']:.2%}")
```

### Return Components (for debugging)
```python
result = energy_fn(z_g, z_e, return_components=True)

# Access intermediate tensors
control_mask = result['control_mask']
importance = result['importance']
deviation = result['deviation']
```

## Known Limitations

1. **Untrained weights:** Current implementation has random initialization
   - Resolution: Requires InfoNCE training on Gatling-10M dataset (LSA-004)

2. **Binary trust semantics:** Treats trust tiers discretely
   - Future: Continuous trust scoring via cryptographic provenance (PA-001)

3. **No temporal awareness:** Analyzes single-step plans only
   - Future: Extend to multi-turn interaction sequences

## Related Components

- **GovernanceEncoder** (LSA-001): Produces z_g input
- **ExecutionEncoder** (LSA-002): Produces z_e input
- **SemanticIntentPredictor** (LSA-003): Feeds into E_scope
- **CompositeEnergy** (EGA-005): Combines all four energy critics
- **RepairEngine** (PA-002): Uses E_hierarchy gradient for plan correction

## References

- PRD Section 2.2: Energy Engine specification
- WORK-DISTRIBUTION.md: Energy Geometry workstream
- Paper: Energy-Based Models (https://arxiv.org/abs/2101.03288)
- Paper: JEPA Architecture (https://arxiv.org/abs/2301.08243)
